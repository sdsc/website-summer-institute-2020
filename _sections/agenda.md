---
location: agenda
head:
  title: SDSC Summer Institute Agenda
---

### <b><font color="#f03c15"> Agenda- To accommodate attendees from different time zones and adhere to guidelines regarding reasonable limits on the duration of direct online instruction, the schedule and content will be subject to change. We do expect though the choice of topics to be generally consistent with previous Summer Institutes. </font></b>
* **Lesson material repository**: <https://github.com/sdsc/sdsc-summer-institute-2020>
* **Lesson material repository for the 2019 edition**: <https://github.com/sdsc/sdsc-summer-institute-2019>
* Chat room: <https://gitter.im/sdsc-summer-institute-2020> (login with your Github account)


## MONDAY, August 3rd

|Time| _Auditorium_ |
|:---:|:-----------|
|8:00 – 8:30 AM | Registration, Coffee |
|8:30 – 10:15 AM | **Welcome** Shawn Strande, Deputy Director, SDSC <br/> **Orientation & Introductions** Bob Sinkovits, Director of Scientific Computing Applications, SDSC - Director of the Summer Institute <br/> **[Accessing and Running Jobs on Comet](https://github.com/sdsc/sdsc-summer-institute-2020/tree/master/3_running_jobs_on_comet)** _Mary Thomas, Computational Data Scientist, SDSC_ <br /> To help you get the most out of your week, this session covers the basics of accessing Comet; managing the user environment;  and compiling and running jobs. It is assumed that you have completed the [basic steps of logging onto Comet and testing your Unix skills before arriving in San Diego](https://github.com/sdsc/sdsc-summer-institute-2020/tree/master/0_preparation) |
| 10:15 - 10:30 AM | break |
| 10:30 - 12:00 PM | Parallel session: <br/> **Introduction to version control with `git` and Github**, _Martin Kandes, Computational Scientist, SDSC_ <br /> Introduction to `git` for beginners, create a repository on Github <br /> <br /> **Advanced `git` & Github**, Andrea Zonca <br/> split session in _Synthesis Center E-B143_ <br/> You should be already familiar with creating Pull Requests, merging and rebasing branches |
| 12:00 – 1:30 PM | Lunch at Café Ventanas |
| 1:30 – 2:15 PM | **Understanding Comet file systems** <br/>  _Manu Shantharam, Senior Computational Scientist, SDSC_ |
| 2:15 - 3:15 PM | **Understanding performance and obtaining hardware information**  <br/>  _Bob Sinkovits_ |
| 3:15 - 3:30 PM | break |
| 3:30 - 4:00 PM | **Introduction to Science Gateways**  <br/>  _Amit Majumdar, Director for Data Enabled Scientific Computing (DESC), SDSC_ <br/> Science Gateways are community-designed web-based interfaces often designed specifically to support a particular type of scientific research and provide access to all kinds of cyberinfrastructure - data collections, instruments, supercomputers, and sensor streams. This talk will introduce science gateways and provide examples of prominent science gateways from various domain sciences. The talk will also cover resources available for building a new gateway including Science Gateways Community Institute (SGCI). |
| 4:00 - 5:00 PM | **An Introduction to Singularity: Containers for Scientific and High-Performance Computing**  <br/>  _Martin Kandes_, Computational & Data Science Research Specialist, SDSC |
| 5:30 – 8:30PM | **Reception- The Bella Vista** <br>2880 Torrey Pines Scenic Drive, La Jolla, CA 92037 <br/> _A short walk off campus, Sweater or jacket recommended_ <br/> |

## TUESDAY, August 4th

| Time | **Track 1** | **Track 2** |
| --- | --- | --- |
| 8:00 – 8:30AM | Coffee | |
| 8:30 – 12:00PM | **Python for HPC** <br/> _Andrea Zonca, Senior Computational Scientist, SDSC_ <br/> In this session we will introduce four key technologies in the Python ecosystem that provide significant benefits for scientific applications run in supercomputing environments. Previous Python experience is recommended but not required. (1) The Jupyter Notebook allows users to execute code on a single compute node through a local browser for interactive data exploration and visualization. The Jupyter Notebook supports live Python code, explanatory text, LaTeX equations and plots in the same document. (2) IPython Parallel provides a simple, flexible and scalable way of running thousands of Python serial jobs by spawning IPython kernels (namely engines) on any HPC batch scheduler. (3) Numba makes it possible to run pure Python code on GPUs simply by decorating functions with the data types of the input and output arguments. Pure Python prototype code can be gradually optimized by pushing the most computationally intensive functions to the GPU without the need to implement code in CUDA or OpenCL. (4) Dask is a flexible parallel computing library that allows to build a distributed computation using simple operators and then let the library automatically handle distributing data, executing the computation hierarchically and gather back the results.  | **A Short Introduction to Data Science and its Applications** <br/> _Subhasis Dasgupta, Computational and Data Researcher, SDSC_ <br/> _Shweta Purawat, Computational and Data Researcher, SDSC_ <br/> _Ilya Zaslavsky, Dr. Spatial Information Systems Lab, SDSC_ <br/> The new era of data science is here. Our lives as well as any field of science, engineering, business and society are continuously transformed by our ability to collect meaningful data in a systematic fashion and turn that into value.  These needs not only push for new and innovative capabilities in composable data management and analytical methods that can scale in an anytime anywhere fashion, but also require methods to bridge the gap between applications and compose such capabilities within solution architectures. In this short overview, we will show you a plethora of applications that are enabled by data science techniques and describe the process and cyberinfrastructure used within these projects to solve questions. We will also overview SDSC's AWESOME and SUAVE platforms for data management and visualization. Particularly, in this session, you will learn about: (1)the basis process of data science, (2) reference solution architectures for computational data science, (3) the data management challenges when deal with steaming data, (4) how social media datasets can be used within scienftific studies, (5) graph analysis at scale, (6) effectively applying basic statistical analysis and machine learning methods to survey data, (7) examples for visualization of datasets through various end user platforms  |
| 12:00 – 1:30 PM | Lunch at Café Ventanas | |
| 1:30 - 5:00 PM | **Performance Tuning** <br/> _Bob Sinkovits, Director for Scientific Computing Applications, SDSC_ <br/> This session is targeted at attendees who both do their own code development and need their calculations to finish as quickly as possible. We&#39;ll cover the effective use of cache, loop-level optimizations, force reductions, optimizing compilers and their limitations, short-circuiting, time-space tradeoffs and more. Exercises will be done mostly in C, but emphasis will be on general techniques that can be applied in any language.  | **Information Visualization**<br/>  _Amit Chourasia, Senior Visualizaton Scientist, SDSC_ <br/> This tutorial will provide a ground up understanding of information visualization concepts and how they can be leveraged to select and use effective visual idioms for different data types such spreadsheet data, geospatial, graph, etc.). Attendees will go through a set of hands on exercises to create designs, decode and fix problems in existing visualization. Practical guidelines for visualization will be discussed as well. |


## WEDNESDAY, August 5th

| Time | **Track 1** | **Track 2** |
| --- | --- | --- |
| 8:00 – 8:30 AM | Coffee | |
| 8:30 – 12:00 PM | **Scientific Visualization with Visit** <br/>  _Amit Chourasia, Senior Visualization Scientist, SDSC_ <br/> This tutorial will provide a high level overview of scientific visualization techniques and their applicability for structured mesh based data (such as rectilinear grids). Attendees will follow along exercises in a hands-on manner to employ different types of techniques using VisIt software and also perform remote visualization on Comet.  | **Machine Learning Overview** <br/>  _Mai Nguyen, Lead for Data Analytics, SDSC_ <br/> _Paul Rodriguez, Research Analyst, SDSC_ <br/> SDSC Machine learning is an interdisciplinary field focused on the study and construction of computer systems that can learn from data without being explicitly programmed. Machine learning techniques can be used to uncover patterns in your data and gain insights into your problem. This session provides an overview of the fundamental machine learning algorithms and techniques used to explore, analyze, and leverage data to construct data-driven solutions applicable to any domain. Topics covered include the machine learning process, data exploration, data preparation, classification, and cluster analysis. Concepts and algorithms will be introduced, followed by exercises to allow hands-on experience using R and RStudio.|
| 12:00 – 1:30 PM | Lunch at Café Ventanas | |
| 1:30 – 1:45 PM | **Group photo** Meet at the staircases in front of the auditorium | |
| 1:45 - 4:30 PM | **Lightning Rounds** | |
| 4:30 - 5PM PM | **Data center tour** | |

## THURSDAY, August 6th

| Time | **Track 1** | **Track 2** |
| --- | --- | --- |
| 8:00 – 8:30 AM | Coffee | |
| 8:30 – 12:00 PM | **GPU Computing and Programming** <br/> _Andreas Goetz, Research Scientist and Principal Investigator, SDSC_ <br/> This session provides an introduction to massively parallel computing with graphics processing units (GPUs). The use of GPUs is becoming increasingly popular across all scientific domains since GPUs can significantly accelerate time to solution for many computational tasks. Participants will be introduced to essential background of the GPU chip architecture and will learn how to program GPUs via the use of libraries, OpenACC compiler directives, and CUDA programming. The session will incorporate hands-on exercises for participants to acquire the skills to use and develop GPU aware applications. | **Scalable Machine Learning** <br/> _Mai Nguyen, Lead for Data Analytics, SDSC_ <br/> _Paul Rodriguez, Research Analyst, SDSC_ <br/> Machine learning is an integral part of knowledge discovery in a wide variety of applications. From scientific domains to social media analytics, the data that needs to be analyzed has become massive and complex. This session provides an introduction to approaches that can be used to perform machine learning at scale. Tools and procedures for executing machine learning techniques on HPC will be presented. Spark will also be covered. In particular, we will use Spark's machine learning library, MLlib, to demonstrate how distributed computing can be used to provide scalable machine learning. Please note: Knowledge of fundamental machine learning algorithms and techniques is required. (See description for Machine Learning Overview.) |
| 12:00 – 1:30 PM | Lunch at Café Ventanas | |
| 1:30 – 5:00 PM | **Parallel Computing using MPI & Open MP** <br/>  _Mahidhar Tatineni, User Services Manager, SDSC_ <br/> This session is targeted at attendees who are looking for a hands-on introduction to parallel computing using MPI and Open MP programming. The session will start with an introduction and basic information for getting started with MPI. An overview of the common MPI routines that are useful for beginner MPI programmers, including MPI environment set up, point-to-point communications, and collective communications routines will be provided. Simple examples illustrating distributed memory computing, with the use of common MPI routines, will be covered. The OpenMP section will provide an overview of constructs and directives for specifying parallel regions, work sharing, synchronization and data scope. Simple examples will be used to illustrate the use of OpenMP shared-memory programming model, and important run time environment variables Hands on exercises for both MPI and OpenMP will be done in C and FORTRAN. | **Deep Learning** <br/>  _Mai Nguyen, Lead for Data Analytics, SDSC_ <br/> _Paul Rodriguez, Research Analyst, SDSC_ <br/> Deep learning, a subfield of machine learning, has seen tremendous growth and success in the past few years.  Deep learning approaches have achieved state-of-the-art performance across many domains, including image classification, speech recognition, and biomedical applications. Deep learning makes use of models that are composed of many layers of interconnected processing units.  The many layers allow for a deep network to learn representations of data at multiple and increasingly complex and task-specific levels of abstraction, leading to automatic feature learning and excellent prediction performance.  This session provides an introduction to deep learning concepts and approaches.  Case studies utilizing deep learning will be presented, and hands-on exercises will be covered using Keras.  Please note:  Knowledge of fundamental machine learning concepts and techniques is required. |
| 5:30 – 9:00 PM | **Beach BBQ Dinner at La Jolla Shores Hotel** , _sweater or jacket recommended_ [8110 Camino Del Oro, La Jolla, CA 92037](https://www.google.com/maps/place/La+Jolla+Shores+Hotel/@32.8549788,-117.2581556,15z/data=!4m2!3m1!1s0x0:0x6e35c24121ff0362?sa=X&ved=0ahUKEwiqvO3JjbHSAhXIjlQKHdJ9CjgQ_BIIczAN) Shuttle provided from SDSC driveway |

## FRIDAY, August 7th

| Time | Title |
| --- | --- |
| 8:00 – 8:30 AM | Coffee |
| 8:30 – 10:00 AM | **Introduction to Research Data Management Using Globus** <br/>_Rick Wagner, Globus Professional Services Manager, Globus_ <br/>Globus is a research data management service developed by the University of Chicago and used by thousands of researchers at institutions in the US and abroad. You will learn about Globus capabilities from the perspective of a researcher, systems administrator, and application developer.  This session will start with a high-level introduction to all aspects of the Globus service, including the web application, command line interface, and platform-as-a-service. Then we’ll review common use cases and demonstrate how the Globus command line interface (CLI) and API may be used to automate repetitive data management tasks, how to use Globus Auth to provide authentication and fine-grained authorization for accessing your own services, and how Globus may be used in conjunction with the Jupyter platform to open up new avenues in interactive data science.|
| 10:15 - 11:45 AM | **SeedMeLab:  Creating data centric websites for researchers and research projects** <br/> _Amit Chourasia, Senior Visualization Scientist, SDSC_ <br/> Data is an integral part of scientific research. With a rapid growth in data collection and generation capability and an increasingly collaborative nature of research activities, data management and data sharing have become central and key to accomplishing research goals. Researchers today have variety of solutions at their disposal from local storage to Cloud based storage. However, most of these solutions focus on hierarchical file and folder organization. While such an organization is pervasively used and quite useful, it relegates information about the data such as description and collaborative notes about the data to external systems. This spread of information into different silos impedes the flow research activities. In this tutorial, we will introduce and provide hands on experience with SeedMeLab platform, which provides a web-based data management and data sharing cyberinfrastructure. Attendees will explore its capabilities and potential for practical use. Learn more at http://seedmelab.org |
| 11:45 – 12:15 PM | **Wrap up** |
| 12:15pm | **Adjourn** Thank you for attending we hope you enjoyed the week!_(To-go box lunches will be available)_ |
